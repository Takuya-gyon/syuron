\documentclass[paper=a4paper,fontsize=11pt]{jlreq}
% パッケージの読み込み
\usepackage{luatexja-fontspec}
\usepackage{graphicx}
\usepackage{enumitem} % カスタマイズ用パッケージ
\usepackage{placeins} % 画像のフロートを防止
\usepackage{caption}
\usepackage{url}
\usepackage{listings} % ソースコードの表示用パッケージ
\usepackage{xcolor}   % カラー指定用
\captionsetup[table]{position=top} % すべての表のキャプションを上にする

\setmainfont{Harano Aji Mincho}
\setsansfont{Harano Aji Gothic}
\setmainjfont{Harano Aji Mincho}
\setsansjfont{Harano Aji Gothic}

%句読点置き換え
\usepackage{newunicodechar}
\newunicodechar{、}{，}
\newunicodechar{。}{．}

\usepackage{amsmath,amssymb}
\usepackage{unicode-math}
\setmathfont{LatinModernMath-Regular}

\graphicspath{{img/}}

\makeatletter
% section の番号を part ごとにリセット
\@addtoreset{section}{part}
\makeatother

% partの番号をアラビア数字に変更
\renewcommand{\thepart}{\arabic{part}}
% section の番号を part番号-○○ にする
\renewcommand{\thesection}{\thepart.\arabic{section}}

% コードのスタイルを定義
\lstset{
  basicstyle=\ttfamily\small,  % フォント
  keywordstyle=\color{blue},   % キーワードの色
  commentstyle=\color{gray},   % コメントの色
  stringstyle=\color{red},     % 文字列の色
  numbers=left,               % 行番号の表示位置
  numberstyle=\small,           % 行番号のフォントサイズ
  stepnumber=1,                % 行番号の間隔
  numbersep=5pt,               % 行番号とコードの間隔
  backgroundcolor=\color{white}, % 背景色
  frame=single,                % 枠のスタイル (single, shadowboxなど)
  breaklines=true,             % 長い行を折り返す
  tabsize=2                    % タブのサイズ
}
% JavaScript のカスタム定義
\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, 
    switch, var, if, in, while, do, else, case, break, const, let, async, await},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{cyan}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{gray}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\renewcommand{\lstlistingname}{ソースコード}


\title{\huge 令和6年度　修士論文\\\vspace{100truept}プログラム読解における\\視線運動のクラスタリング\\
Clustering of Eye Movements\\ in Program Reading}
\author{\large 大阪公立大学大学院　\\情報学研究科　基幹情報学専攻\\学籍番号　BGA23116\\明石　拓也}


\begin{document}
\maketitle
\clearpage

\begin{abstract}
  情報活用能力が必要となった近年において、初等教育からプログラミングが必修化されるなどプログラミング教育の機会は増加している。一方で、プログラミングに長けた指導者の不足が問題視されている。そのため、プログラミング学習の支援となるシステムの重要性が高まっている。学習システム開発のためには、プログラミングを理解している人の読解方法の傾向をつかむことが重要となっている。
  
  これまで、ソースコード読解時の視線運動を対象とした検証が行われている。被験者にソースコード読解を必要とするタスクを課し、読解時の視線運動をアイトラッカーでの計測によりディスプレイ画面上の視線座標という形で取得し、タスクの正誤との関係を調べる分析が主流となっている。また、過去の研究においてプログラミングを理解している人と理解していない人の間にソースコード内の注視場所に違いがあることが示されている。一方、これまでタスクに利用されてきたソースコードは、変数代入や四則演算のみで構成されるもの、条件分岐や繰り返し文を含むものであるが、いずれも単一のクラスを用いた手続き型のソースコードで、数行から数十行程度の短いものである。つまり、既存の研究では、クラスオブジェクト生成やポリモーフィズムなど、オブジェクト指向の概念を取り入れたソースコードでの検証はなされていない。
  
  本論文では、6つのクラスで構成され、オブジェクト生成やメソッド呼び出しを含む百行以上にわたるソースコードを用いて同様の実験を行い、クラス単位という従来の研究よりマクロな視点での分析を行う。また、目標達成のため、エディタでのスクロールを必要とする程度に長いソースコードと視線座標とを対応させるためのエディタのプラグインを開発する。分析結果の検証のため、被験者ごとの6つの各クラスへの注視時間割合を求め、視線運動の傾向を表す6次元のパラメータとする。この傾向を可視化するため、3次元グラフを用いる。6次元データを3次元グラフで可視化するため、主成分分析で次元圧縮をする。
  
  結果として、オブジェクト指向を取り入れたタスクにおいて、正答者の視線運動は3次元グラフ上のある一定の範囲に固まる傾向があり、不正答者のものはよりばらつきが大きいことが分かった。主成分分析での次元圧縮の際に算出した累積寄与率は90％以上と高く、圧縮前のパラメータでもおおむね同様の傾向であるといえる。このことから、オブジェクト指向を取り入れたソースコードを用いたタスクを課すことにより、読解者がコードを理解していない可能性を検知できることが示唆された。
\end{abstract}
\clearpage

\tableofcontents
\clearpage

\part{はじめに}
  \section{本研究の背景}
    情報活用能力が必要となった近年において、プログラミング教育の機会は増加している。
    日本では、2020年度から小学校でプログラミング教育が必修化された\cite{syougaku_program}。
    また、令和７年より大学入試共通テストでも情報Ⅰが必修化され、プログラミングに関する問題が出題されている\cite{tusuto_mondai}。

    一方で、プログラミングに長けた指導者の不足が問題視されている。そのため、プログラミング学習の支援となるシステムの重要性が高まっている。
    学習システム開発のためには、プログラミングを理解している人の読解方法の傾向をつかむことが重要となっている。
    
    これまで、ソースコード読解時の視線運動を対象とした検証が行われている\cite{meiji2021}\cite{hanafusa}\cite{uwano}。
    現在の研究では、被験者にソースコード読解を必要とするタスクを課し、読解時の視線運動をアイトラッカーでの計測により
    ディスプレイ画面上の視線座標という形で取得し、タスクの正誤との関係を調べる分析が主流となっている。
    これまでタスクに利用されてきたソースコードは、変数代入や四則演算のみで構成されるもの、条件分岐や繰り返し文を含むものであるが、
    いずれも単一のクラスを用いた手続き型のソースコードで、数行から十数行程度の短いものである。既存の研究では、クラスオブジェクト生成やポリモーフィズムなど、
    オブジェクト指向の概念を取り入れたソースコードでの検証はなされていない。
  \clearpage
  
  \section{本研究の目的}
    本研究は、短い手続き型ソースコードにおいて読解者のプログラミング理解度によって視線運動に差異が発生するという知見のもと、
    オブジェクト指向を含む長大なソースコードにおいて読解者のプログラミング理解度による視線運動に差異が生じるか否かを明らかにすることを目的とする。
    
  \section{本研究で用いる手段}
    この目的のため、6つのクラスで構成され、オブジェクト生成やメソッド呼び出しを含む百行以上にわたる比較的長大なソースコードを用いて実験を行い、
    クラス単位という従来よりマクロな視点での分析を行う。分析結果の検証のため、被験者ごとの各クラスへの注視時間割合を求め、視線運動の傾向を表すパラメータとする。
    傾向の可視化のため、3次元グラフと2次元グラフを用いる。高次元データを3次元、2次元のグラフで可視化するため、主成分分析で次元圧縮をする。
    \clearpage

  \section{本研究の結果}
    上記の分析を行った結果、オブジェクト指向を取り入れたタスクにおいて、正答者の視線運動は3次元グラフ上のある一定の範囲に固まる傾向があり、
    不正答者のものはよりばらつきが大きいことが分かった。主成分分析での次元圧縮の際に算出した累積寄与率は90％以上と高く、
    圧縮前のパラメータでもおおむね同様の傾向であるといえる。このことから、オブジェクト指向を取り入れたソースコードを用いたタスクにおいても
    プログラミング理解度に応じて視線運動に差異が生じていることが分かった。
  
    次に、分布の違いを利用して未知データの分類が可能といる意見について考察する。今回用いたクラスごとの注視時間割合ベクトルのデータでは、上述の通り
    正解者と不正解者で範囲がきれいに分かれているわけではなく、正解者が一定の範囲に集まり、不正解者がより広い範囲に分散するという結果となった。
    そのため、単純なK-means法やK-medois法などのクラスタリング手法では分類が困難であるといえる。
  
    今後は、より多くのデータを集めて正答者の視線運動の傾向をつかみ、
    その傾向から外れている場合に読解者がコードを理解していない可能性を検知できないか検証することが求められる。
  

  \section{本論文の構成}
    本論文では、以下の構成に従って研究成果の報告を行う。\\
    第２章では本研究に際し採用した手法の説明をする。\\
    第３章では本研究のため行った実験の説明をする。\\
    第４章では実験で得られたデータを加工し、分析する過程とその結果を説明する。\\
    最後に、第５章で本研究のまとめを行う。

\clearpage

\part{採用手法}
  本章では、視線測定に使用するアイトラッカー、データ測定時の課題とその解決策の順で説明する。

  \section{アイトラッカーについて}
    アイトラッカーとは、ディスプレイを見ている被験者の注視点を画面上の座標として取得できる機器である。このアイトラッカーを用いた注視点座標取得の操作をアイトラッキングと呼ぶ。
    主に、ディスプレイの画面に固定して使用するスクリーンベースタイプと、
    ゴーグル型で顔に装着して使用するウェアラブルタイプが存在する。本研究では、Tobii社が提供するスクリーンベースタイプのアイトラッカーである、Tobii Pro Spark\cite{spark}とTobii Nano Pro\cite{nano}を使用する。

    アイトラッカーの仕組みについて、Tobii社は次のように解説している\cite{itracking_sikumi}。
    角膜上に光の反射点を生じさせ、その画像をアイトラッカーの内蔵カメラで撮影する。次に、撮影された眼球画像から角膜上の光の反射点と瞳孔を識別し、それらの情報をもとに眼球の方向を算出する。
    
    この2つの機器を用いた測定時は被験者の顔の位置・角度を適切な位置に固定する必要がある。また、使用する際にはキャリブレーションと呼ばれる操作を行い、アイトラッキングの精度を保つ必要がある。
    さらに、設置位置など、アイトラッカーのパラメータを設定する必要もある。これら3つの設定は、Tobii社が提供するTobii Pro Eye Tracker Manager\cite{manager}というソフトウェアを用いて実現できる。

    図\ref{tobii_nano}に、実験に使用したTobii Pro Nanoの様子を示す。図\ref{tobii_nano}中の赤い四角に示す機器が、ディスプレイ下部に設置されたTobii Pro Nanoである。
    本機器を起動した状態で被験者にディスプレイ画面上の情報を目で追わせ、読解時の各時点における注視点座標をリアルタイムで取得できる。
    Tobii Pro Sparkについても同様である。
    \begin{figure}[htbp]
      \centering
      \includegraphics[width=0.8\linewidth]{tobii_nano.jpg}
      \caption{Tobii Pro Nano}
      \label{tobii_nano}
    \end{figure}
    \FloatBarrier
    \clearpage

    \subsection{Tobii Pro Eye Tracker Manager}
      本研究では、Tobii Pro Eye Tracker Manager\cite{manager}というソフトウェアを用いてアイトラッカーのパラメータ設定やキャリブレーションを行う。
      設定可能なパラメータとして、ディスプレイ画面に対するアイトラッカーの設置位置や角度などがある。

      また、本ソフトを用いたキャリブレーションでは、被験者の顔の適切な位置を画面で確認しながら調節できる。

  \section{先行研究の分析手法}
    本研究では、ソースコードを読解する際の視線座標とソースコード中の要素を対応付ける必要があるが、単純な座標に基づく対応付けではエディタ画面のスクロールが行われた際に対応付けが破綻する問題がある。
    しかし、長大なソースコードを使用する都合上、スクロール操作には対応する必要がある。
    この問題の解決のために使用する手法の紹介をする。

    吉岡らは、アイトラッカーで取得した視線座標からソースコード中の行・列に変換し、さらに構文木に変換するマッピング手法を提案した\cite{meiji2021}。
    変換の手順は以下のとおりである。
    \begin{enumerate}
      \item 視線計測装置が被験者の各時点における注視点をディスプレイ上の座標(例、X:121,Y:313)として時系列に出力する。
      \item 座標-行/列変換モジュールが座標単位の視線移動とソースコードを入力として受け取り、ソースコード名と行/列の組(例、Main.java,行：1,列:13)として出力する。
      \item このとき、得られた行・列番号からソースコード中の単語を抽出し、構文解析で得られた構文木上のノードと対応をとる。
    \end{enumerate}
    
    吉岡らは、このマッピング手法を用いて視線座標をソースコード中の変数名やif,elseなどの単語単位でマッピングしている。
    その後、各単語毎の注視時間割合を求め、正解・不正解ごとの割合の差異を確認している。
  \clearpage    

  \section{本研究の分析手法}
    本研究では、吉岡らが提案したマッピング手法を使用し、アイトラッカー出力の視線座標をソースコード中の要素と対応付ける。
    その後、

  \section{iTraceについて}
    本研究では、前章で述べた視線座標とソースコード中の行・列の対応の実装に、iTrace\cite{itrace}を用いる。iTraceはアイトラッカーでの測定を支援する
    オープンソースのソフトウェア群で、公式サイトおよびGitHubで公開されている。
    主に、アイトラッカーの制御・出力フローの処理等に用いるiTrace Coreと、iTrace Coreの出力を受け取り、
    ソースコードを表示しているエディタの情報と結びつけられるプラグインが用いられる。

    本研究では、iTrace CoreとエディタのプラグインとしてiTrace Atomを使用する。以下に、この2つの詳細を示す。

    \subsection{iTrace Core}
      iTrace Coreは、アイトラッカーの制御や出力フローの処理に使用できる。
      本研究では、アイトラッカーの測定開始・終了操作と、アイトラッカー出力データのプラグインへの受け渡しに使用する。

    \subsection{iTrace Atom}
      iTrace Coreに対応するAtomエディタのプラグインである。Github上で公開されており、ダウンロードして使用できる。閲覧時（2024年9月）は不具合が多く、正常に動作しない状態である。
      そのため、不具合を修正し、以下の機能を完成させる。
      \begin{enumerate}
        \item 視線座標からソースコード中の行・列への変換機能
        \item ソースコード中の行・列からソースコード中の単語への変換機能
        \item 注視中の単語をエディタ上でハイライトする機能
      \end{enumerate}
  \clearpage

  \section{本研究で採用する手法}
    \begin{figure}[htbp]
      \centering
      \includegraphics[width=0.8\linewidth]{実験装置全体図.jpg}
      \caption{実験装置の全体像}
      \label{実験装置全体図}
    \end{figure}
    \FloatBarrier

    図\ref{実験装置全体図}に、本研究で採用する視線データ計測装置の全体図を示す。
    吉岡らが提案したマッピング手法を実装し、アイトラッカーで取得した視線座標を構文木中のクラスと結びつけ、被験者一人一人の視線情報を得る。同時に、被験者のタスクへの解答を取得し、
    タスク正誤情報を得る。
    その後、クラス毎の注視時間割合を求め、正解・不正解ごとの差異を検証する。
  \clearpage

\part{iTrace Atomプラグインの開発}
  実験で使用するiTrace Atomプラグインは、公開されているソースコードを修正・追記する形で実験に使用可能な機能を開発した。
  プラグインの処理に関わるソースコードはJavaScriptで記述されている。

  \section{視線座標を行・列に変換する関数getLineCoumn()}
    完成した関数のソースコードを図\ref{getLineColumn関数}に示す。

    この関数は視線座標をpoint変数として受け取り、row変数とcolumn変数の組を返り値として返す関数である。
    上部（2行目～16行目）で定義されている変数を解説する。
    \begin{table}[h]
      \centering
      \caption{生データに含まれるデータ一覧}
      \begin{tabular}{|c|c|c|}
        \hline
        変数名 & 値の意味 & 格納される型 \\ \hline
        bounds & 操作中のAtomエディタのウィンドウの縦横サイズ[px]の組 & int \\ \hline
        editorWorkingArea & 操作中のソースコードウィンドウの縦横サイズ[px]の組 & int \\ \hline
        overscan & 操作中のソースコードウィンドウの左上端の座標[px] & int \\ \hline
        currentElement & 現在の注視点が位置するソースコード要素 & string \\ \hline
        offsetX &  & \\ \hline
        columnWidth & ソースコード中の半角文字の横幅[px] & int \\ \hline
        row & 出力する列 & int \\ \hline
        column & 出力する行 & int \\ \hline
      \end{tabular}
      \label{getLineColumn_var}
    \end{table}
    \FloatBarrier

    \begin{lstlisting}[language=JavaScript, caption=getLineColumn関数のソースコード, label=getLineColumn]
      getLineColumn(point) {
        const { bounds } = this.screen.getPrimaryDisplay();
        const editorWorkingArea = this.screen.getPrimaryDisplay().workAreaSize;
        const overscan = {
          x: bounds.width - editorWorkingArea.width + 8,
          y: bounds.height - editorWorkingArea.height + 8
        };
        const currentElement = this.document.elementFromPoint(
          point.x - overscan.x,
          point.y - overscan.y
        );
        const offsetX = this.calculateOffsetX();
        const columnWidth = this.getColumnWidth();

        let row = null;
        let column = null;
        if (currentElement === null) {
          return undefined;
        }
        // whitespace
        if (currentElement.classList.contains('line')) {
          row = parseInt(currentElement.getAttribute('data-screen-row'), 10);
          column = Math.floor((point.x - offsetX + this.editerElement.getScrollLeft()) / columnWidth);
        }

        // code element of some sort
        else if (currentElement.className.includes('syntax') || currentElement.className.includes('leading-whitespace')) {
          const line = currentElement.closest('.line');
          row = parseInt(line.getAttribute('data-screen-row'), 10);
          column = Math.floor((point.x - offsetX + this.editerElement.getScrollLeft()) / columnWidth);
        }

        // probably looking outside window
        // todo: map all objects
        else {
          return undefined;
        }

        return { row, column };
      }
    \end{lstlisting}
    
    \pagebreak

\part{実験}
  本章では、実験の目的、実験に際し行った準備、当日の手順、得られたデータの概要を示す。\\
  実験は2章で説明した手法を実装した実験台を3台用意し、被験者を3人ずつ同時並行で測定する。

  \section{実験の目的}
    本実験は、以下の目的で行う。
    \begin{enumerate}
      \item Javaの基礎知識を有する被験者が、複数のクラスで構成され100行以上にわたる比較的長大なJavaソースコードを読解する際の視線情報の収集
      \item 上述のソースコード読解時の被験者のJava理解度の収集
    \end{enumerate}

    この目的達成のため、以下の手段を用いる。
    \begin{enumerate}
      \item 被験者にソースコードと、それに対応するタスクを提示し、思考・解答中の視線座標をアイトラッカーを用いて収集し、視線情報とする
      \item 被験者がタスクに正答した場合はソースコードを理解していると見なし、誤答した場合は理解していないと見なす
    \end{enumerate}

  \section{実験対象}
    実験は、近畿大学工業高等専門学校・総合システム工学科・制御情報コース4年生の学生33名を対象とする。被験者全員がオブジェクト指向を含むJavaプログラミングの授業を受講した経験がある。\\
    なお、被験者全員に以下の事項を伝え、承諾書にサインしていただいた。
    \begin{enumerate}
      \item 実験で使用する装置が身体に害を及ぼさないこと
      \item 計測されたデータを個人を特定できないよう十分配慮した上で研究発表に使用すること
      \item 被験者となるかは任意であり、実験結果が学校の成績等に一切の影響を与えないこと
    \end{enumerate}

  \section{被験者に提示するソースコードとタスク}
    \subsection{ソースコード}
      ソースコードはJavaで記述し、Mainクラスを含む計6つのクラスで構成されるものを準備する。
      コードは148行あり、上部にタスク3～5で使用するクラスを、下部にMainクラスを記述し、行で区切られた範囲に各タスクで使用する文を記述する。
      （図\ref{carbon_clip_main}）。

      図\ref{carbon_clip_class}中のclass Object～からの7行がObjectクラス、class Animal～からの14行がAnimalクラス、
      class Robot～からの26行がRobotクラス、class Person extends Animal～からの15行がPersonクラス、
      class Cat extends Animal～からの14行がCatクラスの記述である。Personクラス、CatクラスはAnimalクラスを継承している。

      また、図\ref{carbon_clip_main}に示すMainクラスには各タスクで使用するソースコードが区切られて順番に記述されている。
      各タスクのソースコードは独立しており、区切りの中のコードと図\ref{carbon_clip_class}のクラス定義文のみを読んでタスクに解答できる。
      \begin{lstlisting}[language=Java, caption=実験で被験者に提示したソースコード]
        class Object {
            private String name;

            public void setName(String name) {
                this.name = name;
            }
        }

        class Animal {
            private String name;

            public void setName(String name) {
                this.name = name;
            }
            public String getName() {
                return this.name;
            }

            public void speak() {
                System.out.println("モーモー！");
            }
        }

        class Robot {
            private String os;
            private int x;
            private int y;
            private String name;

            public void setName(String name) {
                this.name = name;
            }
            public String getName() {
                return this.name;
            }

            public void setOs(String os) {
                this.os = os;
            }
            public void setNumber(int x, int y) {
                this.x = x;
                this.y = y;
            }

            public void process() {
                int out = x * y;
                System.out.println(this.os + "出力：" + out);
            }
        }

        class Person extends Animal {
            private int age;

            public void setAge(int age) {
                this.age = age;
            }
            public int getAge() {
                return age;
            }

            public void speak() {
                int futureAge = age + 5;
                System.out.println("人間です！");
            }
        }

        class Cat extends Animal {
            private int age;

            public int getAge() {
                return age;
            }
            public void setAge(int age) {
                this.age = age;
            }

            public void speak() {
                System.out.println("ニャー！");
            }
        }

        public class Main {
            public static void main(String[] args) {
        //=====================================================
                //１問目（1分）
                int x = 3;
                if(x > 5){
                    x = 0;
                    if(x < 2){
                        System.out.println("A");
                    }
                    else{
                        System.out.println("B");
                    }
                }
                else if(x <= 5){
                    x = 10;
                    if(x > 5){
                        x = 7;
                        System.out.println("C");
                    }
                    else if(x == 7){
                        System.out.println("D");
                    }
                    else{
                        System.out.println("E");
                    }
                }

        //=====================================================
                //２問目（1分）
                int[] indexes = {1, 3, 4, 6};
                int[] array = {8, 3, 9, 4, 2, 4, 6, 8, 1, 5};

                int sum = 0;
                for(int i = 0; i < indexes.length; i++){
                    sum += array[indexes[i]];
                }

                System.out.println(sum);

        //=====================================================
                //３問目(2分)
                Robot robot = new Robot();
                robot.setOs("Windows");
                robot.setNumber(2, 3);
                robot.process();

        //=====================================================
                //４問目(2分)
                Person person = new Person();

                person.setName("Taro");
                person.setAge(25);

        //=====================================================
                //５問目(2分)
                Animal animal1 = new Person();
                Animal animal2 = new Cat();
                Animal animal3 = new Animal();

                animal1.speak();
                animal2.speak();
                animal3.speak();

        //=====================================================
            }
        }
      \end{lstlisting}

  \subsection{タスク}
    タスクは全5問用意する。うち2問がオブジェクト指向の概念を伴わないMainクラス内で完結するタスク、うち3問がオブジェクト指向の概念を伴うタスクである。
    ソースコード\ref{task1}～ソースコード\ref{task5}にタスクの詳細を示す。\\
    \begin{enumerate}[label=タスク\arabic*:]
      \item ソースコード\ref{task1}に示すコードの読解を課す。変数代入とif文による条件分岐を組み合わせたタスク。標準出力の出力結果を答えさせる。オブジェクト指向の概念を伴わない。
      \begin{lstlisting}[language=Java, caption=タスク1のソースコード, label=task1]
        //１問目（1分）
        int x = 3;
        if(x > 5){
            x = 0;
            if(x < 2){
                System.out.println("A");
            }
            else{
                System.out.println("B");
            }
        }
        else if(x <= 5){
            x = 10;
            if(x > 5){
                x = 7;
                System.out.println("C");
            }
            else if(x == 7){
                System.out.println("D");
            }
            else{
                System.out.println("E");
            }
        }
      \end{lstlisting}
      \pagebreak

      \item ソースコード\ref{task2}に示すコードの読解を課す。配列の参照を使用したタスク。標準出力の出力結果を答えさせる。オブジェクト指向の概念を伴わない。
      \begin{lstlisting}[language=Java, caption=タスク2のソースコード, label=task2]
        //２問目（1分）
        int[] indexes = {1, 3, 4, 6};
        int[] array = {8, 3, 9, 4, 2, 4, 6, 8, 1, 5};

        int sum = 0;
        for(int i = 0; i < indexes.length; i++){
            sum += array[indexes[i]];
        }

        System.out.println(sum);
      \end{lstlisting}

      \item ソースコード\ref{task3}に示すコードの読解を課す。1種類のクラスを使用し、オブジェクト生成と外部からのメソッド実行を含むタスク。標準出力の出力結果を答えさせる。オブジェクト指向の概念を伴う。
      \begin{lstlisting}[language=Java,caption=タスク3のソースコード, label=task3]
        //３問目(2分)
        Robot robot = new Robot();
        robot.setOs("Windows");
        robot.setNumber(2, 3);
        robot.process();
      \end{lstlisting}

      \item ソースコード\ref{task4}に示すコードの読解を課す。2種類のクラスを使用し、オブジェクト生成とセッターの呼び出しを含むタスク。2種類のクラスは片方がもう片方を継承する関係にある。
      ソースコード内で、それぞれのオブジェクトのセッターが定義された行を答えさせる。オブジェクト指向の概念を伴う。
      \begin{lstlisting}[language=Java,caption=タスク4のソースコード, label=task4]
        //４問目(2分)
        Person person = new Person();

        person.setName("Taro");
        person.setAge(25);
      \end{lstlisting}
      \pagebreak

      \item ソースコード\ref{task5}に示すコードの読解を課す。3種類のクラスを使用し、メソッドのオーバーライドを含む。標準出力の出力結果を答えさせる。オブジェクト指向の概念を伴う。
      \begin{lstlisting}[language=Java,caption=タスク5のソースコード, label=task5]
        //５問目(2分)
        Animal animal1 = new Person();
        Animal animal2 = new Cat();
        Animal animal3 = new Animal();

        animal1.speak();
        animal2.speak();
        animal3.speak();
      \end{lstlisting}
    \end{enumerate}

    \pagebreak

  \section{実験台の構成}
    1つの実験台につき一人を座らせ、視線運動の測定を行う。
    本実験では、測定の効率化のため被験者3人ずつ同時に測定を行うため、実験台は計3台用意する。
    各実験台を構成する機器を以下に示す。

    \begin{enumerate}
      \item ディスプレイ 
      
      3台の実験台全てに、画面サイズ1920×1200ピクセルのディスプレイを使用する。
      
      \item コンピュータ
      
      3台の実験台全てに、Windows11がセットアップされたコンピュータを使用する。
      コンピュータにはあらかじめTobii Pro Eye Tracker Manager、iTrace Coreと、
      iTrace AtomプラグインがインストールされたAtomエディタをインストールする。
      
      \item アイトラッカー
      
      3台の実験台のうち、2台にTobii Pro Sparkを搭載し、1台にTobii Pro Nanoを搭載する。
      3台全てにおいてディスプレイ画面下に設置する。
      
      \item マウス
      
      3台の実験台全てに、被験者にエディタを操作していただくため用意する。
      
      \item 顎台
      
      3台の実験台全てに、被験者の顔を固定可能な顎台を用意する。
      本実験は測定時間が約8分と長く、またタスクの間には解答用紙記述のため画面から目を離す必要があるため、
      被験者が顔の適切な位置を見失うことが想定される。そのため、顔の位置を固定可能な台を用意し、
      アイトラッキングの精度を保つことが必要となる。
    \end{enumerate}

    図\ref{実験部屋}に、実験部屋に設置した3台の実験台の様子を示す。
    ディスプレイの右上端にA,B,Cの記号が書かれた紙を貼り、各実験台を区別する。
    被験者は椅子に座り、顎台に顔を置いた状態で実験を受ける。
    机上のキーボードは実験運営側の操作に使用する。
    
          
    \begin{figure}[htbp]
      \centering
      \includegraphics[width=0.8\linewidth]{実験部屋.jpg}
      \caption{実験部屋の様子}
      \label{実験部屋}
    \end{figure}
    \FloatBarrier  
  \clearpage

  \section{実験手順}
    実験は、以下の手順で行う。
    \begin{enumerate}
      \item 実験台のセットアップ
      \item 承諾書記入
      \item キャリブレーション
      \item 実験の詳細説明
      \item 練習問題
      \item 5つのタスク提示・視線座標計測
    \end{enumerate}
    実験手順を詳細に解説する。

    \subsection{実験台のセットアップ}
      被験者の交代の度に実験台を図\ref{実験台}のようにセットアップする。
      画面にはAtomエディタ、iTrace Core、Tobii Pro Eye Tracker Managerのウィンドウを表示させ、
      後の測定が円滑にする。iTrace CoreはStart/Stopボタンが常に見える位置に配置する。
      Atomエディタには練習問題のソースコードを表示しておく。
      机上には解答用紙と承諾書を配置しておく。

      \begin{figure}[h]
        \centering
        \includegraphics[height=0.5\linewidth]{実験台.jpg}
        \caption{セットアップされた実験台の画面}
        \label{実験台}
      \end{figure}
    
    \subsection{承諾書記入}
      被験者に承諾書の内容を確認していただき、サインしていただく。
      承諾書はセットアップ時に机上に配置し、サインが終わり次第回収する。
    
    \subsection{キャリブレーション}
      まず、Tobii Pro Eye Tracker Managerが示す適切な顔の位置に顎台を固定する。
      固定ができ次第キャリブレーションを行う。
      要再測定の表示が出た場合は再測定をする。

    \subsection{実験の詳細説明}
      被験者に以下の事項をお伝えする。
      \begin{enumerate}
        \item ソースコードを読解しながらタスクを解くこと
        \item 測定終了まで顎台から顔を離さず、首を動かさないこと
        \item ソースコード読解時はエディタのスクロール操作のみ行い、書き込みはしないこと
        \item 問題が解き終わり次第、挙手で合図を出して画面から目をそらし、解答用紙に記入すること
      \end{enumerate}
    
    \subsection{練習問題}
      計測の前に、被験者に実験に慣れていただくことと、データが正しく取れることの確認のため、練習問題を実施する。
      問題の内容は練習問題用ソースコードの全ての行を読むこととする。
      練習問題終了時にデータ保存先フォルダを確認し、正しく保存されているかを確認する。

    \subsection{5つのタスク提示・視線座標計測}
      測定用ソースコードとタスクを提示し、被験者に解いていただく。
      各タスクごとに測定用ソースコードのMainクラス内に記述された読解開始の合図と同時にタスクの内容を口頭で説明する。
  \clearpage

  \section{実験結果}
    実験により、計33人の視線座標データを取得した。そのうち、正確に保存されなかったデータと測定時のプログラムに誤りがあったデータを除き、
    後の分析に使用できるデータを抽出する。抽出後のタスクごとのデータ数と、正誤数を表\ref{data_num}に示す。
    なお、タスク5において、3つある解答のうち、それぞれの内容はあっているものの記述順が異なっている場合に「惜しい」判定とする。\\
    \begin{table}[h]
      \centering
      \caption{実験により取得された使用可能データと、各タスクごとの正誤数}
      \begin{tabular}{|c|c|c|c|c|}
        \hline
        タスク名&使用可能なデータ数&正答数&誤答数&惜しい\\ \hline
        タスク1&26&6&20&-\\ \hline
        タスク2&10&3&7&-\\ \hline
        タスク3&10&3&7&-\\ \hline
        タスク4-1&26&2&24&-\\ \hline
        タスク4-2&26&7&19&-\\ \hline
        タスク5&26&13&8&5\\ \hline
      \end{tabular}
      \label{data_num}
    \end{table}
   \FloatBarrier


\clearpage

\part{データの分析}
  本章では、実験で得られたデータを加工し、6つのクラスごとの注視時間割合に変換する過程と、その後の分析の一連の流れを示す。
  データは加工の過程で生データxml、変数付きcsv、注視時間割合の順に変換される。
  変換後の6次元の注視時間割合ベクトルを主成分分析で3次元、2次元に圧縮し、3Dプロット、2Dプロットに描画して観察する。

  \section{生データxmlから注視時間割合までの処理}
    実験により得られた生データはxml形式で保存される。表\ref{n_data}に、生データが持つパラメータを記す。
    \begin{table}[h]
      \centering
      \caption{生データに含まれるデータ一覧}
      \begin{tabular}{|c|c|c|}
        \hline
        パラメータ名 & 値の意味 & 値の例 \\ \hline
        screen\_width & ディスプレイ画面の横px数 & 1920 \\ \hline
        screen\_height & ディスプレイ画面の縦px数 & 1200 \\ \hline
        plugin\_type & プラグインの種類 & ATOM \\ \hline
        gaze & 視線情報 & 後述 \\ \hline
      \end{tabular}
      \label{n_data}
    \end{table}
   \FloatBarrier

  gazeパラメータはアイトラッカーのサンプリング数だけ存在し、それぞれ表\ref{gaze_data}のパラメータを持つ。
  なお、アイトラッカーのサンプリングレートはTobii Pro Spark、Tobii Pro Nanoともに60Hzである。

  \begin{table}[h]
    \centering
    \caption{生データに含まれる視線情報}
    \begin{tabular}{|c|c|c|}
        \hline
        パラメータ名 & 値の意味 & 値の例 \\ \hline
        event\_id & 2 & 133784518694431017 \\ \hline
        plugin\_time & サンプリングのUNIX時間[ms] & 1733978269442 \\ \hline
        x & ディスプレイ画面上のx座標[px] & 480 \\ \hline
        y & ディスプレイ画面上のy座標[px] & 418 \\ \hline
        source\_file\_line & ソースコード中の行 & 2 \\ \hline
        source\_file\_col & ソースコード中の列 & 9 \\ \hline
        word & 視線が位置していた単語 & int \\ \hline
        gaze\_target & 視線が位置していたファイルの名前 & Problem1.java \\ \hline
        gaze\_target\_type & 対象ファイルの拡張子 & java \\ \hline
        source\_file\_path & 対象ファイルのファイルパス & Problem1.java \\ \hline
        editor\_line\_height & エディタの行の高さの設定値 & 40 \\ \hline
        editor\_font\_height & エディタのフォントサイズの設定値 & 120 \\ \hline
    \end{tabular}
    \label{gaze_data}
  \end{table}
  \FloatBarrier
  
  上述の生データから特定の情報を抜き出し、プログラムで扱いやすいようcsvに加工する。
  この際、サンプリング間の速度とAOI(Area Of Instance)も計算し、csvの列に加える。計算後の変数付きcsvの主なパラメータを表\ref{csv_data}に示す。
  \begin{table}[h]
    \centering
    \caption{変数付きcsvの主なパラメータ}
    \begin{tabular}{|c|c|c|}
        \hline
        パラメータ名 & 値の意味 & 値の例 \\ \hline
        time & 計測開始からの経過時間[ms] & 123 \\ \hline
        x & ディスプレイ画面上のx座標[px] & 480 \\ \hline
        y & ディスプレイ画面上のy座標[px] & 418 \\ \hline
        line & ソースコード中の行 & 2 \\ \hline
        col & ソースコード中の列 & 9 \\ \hline
        velocity & 速さ[px/ms] & 0.5893286\\ \hline
        AOI & クラス番号 & 1\\ \hline
    \end{tabular}
    \label{csv_data}
  \end{table}
  \FloatBarrier


  求めた変数付きcsvから、6つのクラスごとの注視時間割合ベクトルを算出する。
  
  \section{3D・2Dプロットの観察}
    求めた被験者ごとの注視時間割合ベクトルを主成分分析にて3次元、2次元に落とし、それぞれ3Dプロット,2Dプロットで可視化する。
    各被験者をドットとし、タスクの正誤ごとに色分けして表示する。色分けは、正解者が青、不正解者が赤、惜しいが緑とする。
    \pagebreak

    \subsection{タスク3}
      タスク3の分布について、図\ref{3dplot_q3}に3Dプロットを、図\ref{2dplot_q3}に2Dプロットを示す。
      図\ref{3dplot_q3}の3Dプロットについて、正解者は一定の場所に固まり、不正解者は表示範囲全体に広がっている。
      また、図\ref{2dplot_q3}の2Dプロットについて、正解者は右上に固まっており、不正解者は表示範囲全体に広がっている。
      \begin{figure}[htbp]
        \centering
        \includegraphics[width=0.8\linewidth]{3dplot_q3.png}
        \caption{タスク3の分布（3Dプロット）}
        \label{3dplot_q3}
      \end{figure}
      \FloatBarrier
      \begin{figure}[htbp]
        \centering
        \includegraphics[width=\linewidth]{2dplot_q3.jpg}
        \caption{タスク3の分布（2Dプロット）}
        \label{2dplot_q3}
      \end{figure}
      \FloatBarrier
      \pagebreak

    \subsection{タスク4}
      タスク4の分布について、図\ref{3dplot_q4_2}に3Dプロットを、図\ref{2dplot_q4_2}に2Dプロットを示す。
      図\ref{3dplot_q4_2}の3Dプロットについて、正解者は中央右寄りに分布し、不正解者は中央から右側にかけて分布している。
      また、図\ref{2dplot_q4_2}の2Dプロットについて、正解者は中央左寄りに固まっており、不正解者は中央から左側にかけて広がっている。
      \begin{figure}[htbp]
        \centering
        \includegraphics[width=0.8\linewidth]{3dplot_q4_2.png}
        \caption{タスク4-2の分布（3Dプロット）}
        \label{3dplot_q4_2}
      \end{figure}
      \FloatBarrier
      \begin{figure}[htbp]
        \centering
        \includegraphics[width=\linewidth]{2dplot_q4_2.jpg}
        \caption{タスク4-2の分布（2Dプロット）}
        \label{2dplot_q4_2}
      \end{figure}
      \FloatBarrier
      \pagebreak

    \subsection{タスク5}
      タスク5の分布について、図\ref{3dplot_q5}に3Dプロットを、図\ref{2dplot_q5}に2Dプロットを示す。
      図\ref{3dplot_q5}の3Dプロットについて、正解者は上部に広く分布し、不正解者と惜しいは中央と右側に分かれて分布している。
      また、図\ref{2dplot_q5}の2Dプロットについて、正解者は中央から左側にかけて分布し、不正解者は表示範囲に散らばり、惜しいは中央右寄りと左側に分布している。
      \begin{figure}[htbp]
        \centering
        \includegraphics[width=0.8\linewidth]{3dplot_q5.png}
        \caption{タスク5の分布（3Dプロット）}
        \label{3dplot_q5}
      \end{figure}
      \FloatBarrier
      \begin{figure}[htbp]
        \centering
        \includegraphics[width=\linewidth]{2dplot_q5.jpg}
        \caption{タスク5の分布（2Dプロット）}
        \label{2dplot_q5}
      \end{figure}
      \FloatBarrier
      \pagebreak

    \subsection{考察}
      タスク3、タスク4、タスク5において、正答者のプロットは不正解者のものと比較して固まって位置する傾向にあることが分かる。
      特に、タスク3においては正解者と不正解者の分布範囲に明らかな違いが見られる。これは、タスク3ではRobotクラスのみが使用されるために、
      ソースコードの動作を理解している人はMainクラスとRobotクラスの範囲に集中していることが原因と考えられる。
      逆に、タスク5においては正解者の分布が他のタスクと比較して散らばっている。これはタスク5が3つのクラスの読解を必要とするため、
      ソースコードの動作を理解している被験者においても視線がソースコードのクラス定義文の範囲全体に散らばりやすく、理解していない被験者との差が
      生まれにくいことが原因と考えられる。
      また、全てのタスクにおいて不正解者の分布が全体に散らばっている傾向にあるが、これは不正解者は
      共通した特定の読解方法を持たず、おのおのが異なる読解を行うことが原因と考えられる。

    \pagebreak

\part{結論}
  本研究により、オブジェクト指向を取り入れたタスクにおいて、正答者の視線運動は3次元グラフ上のある一定の範囲に固まる傾向があり、
  不正答者のものはよりばらつきが大きいことが分かった。主成分分析での次元圧縮の際に算出した累積寄与率は90％以上と高く、
  圧縮前のパラメータでもおおむね同様の傾向であるといえる。このことから、オブジェクト指向を取り入れたソースコードを用いたタスクにおいても
  プログラミング理解度に応じて視線運動に差異が生じていることが分かった。

  次に、分布の違いを利用して未知データの分類が可能といる意見について考察する。今回用いたクラスごとの注視時間割合ベクトルのデータでは、上述の通り
  正解者と不正解者で範囲がきれいに分かれているわけではなく、正解者が一定の範囲に集まり、不正解者がより広い範囲に分散するという結果となった。
  そのため、単純なK-means法やK-medois法などのクラスタリング手法では分類が困難であるといえる。

  今後は、より多くのデータを集めて正答者の視線運動の傾向をつかみ、
  その傾向から外れている場合に読解者がコードを理解していない可能性を検知できないか検証することが求められる。

\pagebreak

\part*{謝辞}
  本研究は,
  研究生活を通して熱心にご指導賜りました、指導教員の大阪公立大学大学院情報学研究科・基幹情報学専攻の大野修一教授,
  共同で研究に励むと同時に、研究を導いて下さりました岩佐英彦先生,
  修士論文審査において貴重なご助言を賜りました大阪公立大学大学院情報学研究科・基幹情報学専攻の戸出英樹教授、上野敦志講師、
  視線測定実験の共同運営にご尽力頂きました近畿大学工業高等専門学校・総合システム工学科・制御情報コース5年生の岡村晏志様、
  および視線測定実験にご同意・ご協力頂きました近畿大学工業高等専門学校・総合システム工学科・制御情報コース4年生33名の協力により得られた成果です.ここに記して謝意を表します.

\pagebreak

\begin{thebibliography}{99}
  \bibitem{syougaku_program} 文部科学省,"小学校プログラミング教育の手引（第三版）",文部科学省,\url{https://www.mext.go.jp/a_menu/shotou/zyouhou/detail/1375607.htm},（参照：2025-2-13）
  \bibitem{tusuto_mondai} 大学入試センター,"情報 サンプル問題",文部科学省,\url{https://www.mext.go.jp/content/20211014-mxt_daigakuc02-000018441_9.pdf},（参照：2025-2-13）
  \bibitem{meiji2021} 泰地 酒井, 昌一 浦野,視線分析の傾向分析による特徴抽出,人工知能学会全国大会論文集,2021
  \bibitem{hanafusa} 亮 花房, 慎平 松本, 雄介 林, 宗 平嶋,視線運動を用いたプログラム読解パターンのデータ依存関係に基づく分析
  ーー代入演算と算術演算で構成されるプログラムを対象としてーー,教育システム情報学会誌,2018
  \bibitem{uwano} 吉岡春彦,上野秀剛,構文木と視線移動の自動マッピング手法を用いたプログラム理解過程の分析,ソフトウェアエンジニアリングシンポジウム2023,2023
  \bibitem{spark} Tobii Pro Spark https://www.tobii.com/ja/products/eye-trackers/screen-based/tobii-pro-spark
  \bibitem{nano} Tobii Pro Nano https://www.tobii.com/ja/products/discontinued/tobii-pro-nano
  \bibitem{itracking_sikumi} tobii,"アイトラッキングの基礎１　アイトラッカーの仕組み",tobii公式サイト,https://www.tobii.com/ja/blog/how-eye-tracking-working,（参照：2025-2-21）
  \bibitem{manager} Tobii Pro Eye Tracker Manager https://connect.tobii.com/s/etm-download
  \bibitem{itrace} iTrace https://www.i-trace.org/
  \bibitem{atom} ATOM https://atom-editor.cc/
\end{thebibliography}


\end{document}
